## GPT/ELMO/XLNET/NEZHA

**GPT1.0/GPT2.0(OpenAI)**

- GPT1.0要点：
  - 采用Transformer进行特征抽取，首次将Transformer应用于预训练语言模型；
  - finetune阶段引入语言模型辅助目标（辅助目标对于大数据集有用，小数据反而有所下降，与SiATL相反），解决finetune过程中的灾难性遗忘；
  - 预训练和finetune一致，统一2阶段框架；
- GPT2.0要点：
  - 没有针对特定模型的精调流程：GPT2.0认为预训练中已包含很多特定任务所需的信息。
  - 生成任务取得很好效果，使用覆盖更广、质量更高的数据；
- 缺点：
  - 依然为单向自回归语言模型，无法获取上下文相关的特征表示；

**ELMO(华盛顿大学)**

- 要点：
  - 引入双向语言模型，其实是2个单向语言模型（前向和后向）的集成；
  - 通过保存预训练好的2层LSTM，通过特征集成或finetune应用于下游任务；
- 缺点：
  - 本质上为自回归语言模型，只能获取单向的特征表示，不能同时获取上下文表示；
  - LSTM不能解决长距离依赖。
- 为什么不能用biLSTM构建双向语言模型？
  - 不能采取2层biLSTM同时进行特征抽取构建双向语言模型，否则会出现**标签泄漏**的问题；因此ELMO前向和后向的LSTM参数独立，共享词向量，独立构建语言模型；

**XLNET**

- Permutation Language Model(简称PLM,排序模型)；这个可以理解为在自回归LM模式下，如何采取具体手段，来融入双向语言模型。
- 引入了Transformer-XL的主要思路：相对位置编码以及分段RNN机制。处理过长文本
- 加大增加了预训练阶段使用的数据规模

**NEZHA**

- 相对位置编码，每一层计算隐状态的相互依赖的时候考虑他们之间的相对位置关系
- 全词遮盖
- 训练过程中采用混合精度训练，将训练速度提高到2-3倍，还可以减少模型的空间消耗
- 优化器采用LAMB(Large Batch Optimization for Deep Learning：Training BERT in 76 minutes)，LAMB优化器通过一个自适应式的方式为每个参数调整learning rate，能够在Batch Size很大的情况下不损失模型的效果，使得模型训练能够采用很大的Batch Size，进而极大提高训练速度。

